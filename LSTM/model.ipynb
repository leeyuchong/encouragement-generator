{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "venv",
   "display_name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import csv"
   ]
  },
  {
   "source": [
    "<h1>Text preprocessing</h1>\n",
    "Code adapted from: https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num samples posts:  965\nNum samples comments output 965\nNum samples comments input 965\nwhen we started dating 5 years ago , i told her how much i wanted children . she said she could want kids with me . apparently , she is changed her mind and does not want kids at all now , and i just do not think i could be fulfilled without children . i do not want to lose her and our dog . i just feel so bad right now .\nim really sorry to hear that . may i ask why she doesnt want children ? or perhaps ask her why if you havent already . is she open to adopting maybe ? <END>\n<START> im really sorry to hear that . may i ask why she doesnt want children ? or perhaps ask her why if you havent already . is she open to adopting maybe ?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.replace(\"i'm\", \"i am\")\n",
    "    # text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = text.replace(\"he's\", \"he is\")\n",
    "    text = text.replace(\"she's\", \"she is\")\n",
    "    text = text.replace(\"it's\", \"it is\")\n",
    "    text = text.replace(\"what's\", \"that is\")\n",
    "    text = text.replace(\"that's\", \"that is\")\n",
    "    text = text.replace(\"where's\", \"where is\")\n",
    "    text = text.replace(\"how's\", \"how is\")\n",
    "    text = text.replace(\"\\'ll\", \" will\")\n",
    "    text = text.replace(\"\\'re\", \" are\")\n",
    "    text = text.replace(\"\\'ve\", \" have\")\n",
    "    text = text.replace(\"\\'d\", \" would\")\n",
    "    text = text.replace(\"won't\", \"will not\")\n",
    "    text = text.replace(\"can't\", \"cannot\")\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"n'\", \"ng\")\n",
    "    text = text.replace(\"'bout\", \"about\")\n",
    "    text = text.replace(\"'til\", \"until\")\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # if text != \":)\" or text != \":(\":\n",
    "    #     text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "start_char = \"<START>\"\n",
    "end_char = \"<END>\"\n",
    "\n",
    "posts = []\n",
    "comments_output = []\n",
    "comments_input = []\n",
    "\n",
    "with open('../encouragement_comments.csv', 'r', newline='') as csv_file:\n",
    "    textReader = csv.reader(csv_file)\n",
    "    for row in textReader:\n",
    "        cleaned_text = clean_text(row[1])\n",
    "        posts.append(\" \".join(re.findall(r\"[\\w']+|[.,!?;]\", cleaned_text)))\n",
    "\n",
    "        cleaned_text = clean_text(row[0])\n",
    "        cleaned_text = re.findall(r\"[\\w']+|[.,!?;]\", cleaned_text)\n",
    "        cleaned_text = [ x.strip() for x in cleaned_text ]\n",
    "        cleaned_text = [start_char] + cleaned_text + [end_char]\n",
    "        comments_output.append(\" \".join(cleaned_text[1:]))\n",
    "        comments_input.append(\" \".join(cleaned_text[:-1]))\n",
    "print(\"Num samples posts: \", len(posts))\n",
    "print(\"Num samples comments output\", len(comments_output))\n",
    "print(\"Num samples comments input\", len(comments_input))\n",
    "print(posts[500])\n",
    "print(comments_output[500])\n",
    "print(comments_input[500])"
   ]
  },
  {
   "source": [
    "# Generate all the unique words in the data set\n",
    "all_words = set()\n",
    "all_text = posts + comments_output + comments_input\n",
    "for sentence in all_text:\n",
    "    for word in sentence.split():\n",
    "        all_words.add(word)\n",
    "print(\"Total number of unique words: \", len(all_words))\n",
    "\n",
    "for i, word in enumerate(all_words):\n",
    "    if i < 5:\n",
    "        print(word)\n",
    "    else: break"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of unique words:  8453\nrifle\nuh\nur\n2016\nlies\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total unique words:  8453\nMax post length:  3501\nAverage post length:  202.76269430051815\nmedian_post_length:  134.0\nMax comment length:  923\nAverage comment length:  95.30259067357512\n95.30259067357512\nmedian_comment_length:  66.0\n203\n95\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy import stats\n",
    "\n",
    "vocab_size = len(all_words)\n",
    "tokenizer = Tokenizer(num_words = vocab_size+1, filters='', lower=False)\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "word_to_index = tokenizer.word_index\n",
    "\n",
    "print(\"Total unique words: \", len(word_to_index))\n",
    "\n",
    "posts_sequence = tokenizer.texts_to_sequences(posts)\n",
    "MAX_POST_LEN = max(len(seq) for seq in posts_sequence)\n",
    "average_post_length = np.average([len(seq) for seq in posts_sequence])\n",
    "median_post_length = np.median([len(seq) for seq in posts_sequence])\n",
    "print(\"Max post length: \", MAX_POST_LEN)\n",
    "print(\"Average post length: \", average_post_length)\n",
    "print(\"median_post_length: \", median_post_length)\n",
    "\n",
    "comments_output_sequence = tokenizer.texts_to_sequences(comments_output)\n",
    "comments_input_sequence = tokenizer.texts_to_sequences(comments_input)\n",
    "MAX_COMMENT_LEN = max(len(seq) for seq in comments_output_sequence)\n",
    "average_comment_length = np.average([len(seq) for seq in comments_output_sequence])\n",
    "median_comment_length = np.median([len(seq) for seq in comments_output_sequence])\n",
    "print(\"Max comment length: \", MAX_COMMENT_LEN)\n",
    "print(\"Average comment length: \", average_comment_length)\n",
    "print(np.average([len(seq) for seq in comments_input_sequence]))\n",
    "print(\"median_comment_length: \", median_comment_length)\n",
    "\n",
    "AVG_POST_LEN = int(round(average_post_length))\n",
    "print(AVG_POST_LEN)\n",
    "AVG_COMMENT_LEN = int(round(average_comment_length))\n",
    "print(AVG_COMMENT_LEN)\n",
    "\n",
    "# index_to_word = dict()\n",
    "# for k, v in word_to_index.items():\n",
    "#     index_to_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[57, 2077, 6, 200, 17, 7, 3917, 36, 3196, 881, 36, 1252, 27, 125, 3144, 109, 51, 1, 6, 33, 20, 9, 30, 99, 7, 341, 12, 35, 1209, 7, 299, 738, 169, 242, 6, 4225, 4, 20, 394, 155, 1, 6, 2975, 3, 6, 576, 3, 17, 7, 739, 11, 1429, 3, 5821, 418, 3, 2730, 3, 5822, 3, 962, 3, 5, 273, 20, 7, 2819, 125, 64, 4, 4028, 1, 42, 16, 2055, 787, 112, 238, 2, 92, 55, 74, 15, 16, 72, 881, 32, 10, 9, 335, 4, 196, 637, 27, 7], [57, 55, 2, 32, 15, 226, 3, 2, 383, 4, 535, 15, 1028, 953, 1281, 639, 27, 5834, 1, 617, 1263, 5835, 3, 128, 9, 7, 118, 34, 6, 24, 15, 76, 11, 7, 96, 1], [57], [57, 22, 224, 3, 16, 219, 6, 552, 12, 650, 7, 115, 1415, 1, 5836, 5837, 2534, 5838, 518, 5839, 1, 617, 5840, 5841, 2195, 22, 224, 1, 6, 24, 14, 250, 1, 52, 24, 40, 650, 8, 188, 1415, 91, 154, 91, 3, 5, 9, 174, 37, 604, 27, 45, 1, 6, 1131, 4, 606, 10, 40, 165, 487, 435, 24, 26, 435, 1, 67, 20, 14, 391, 155, 3, 5, 67, 24, 14, 1671, 623, 1, 6, 33, 37, 41, 11, 582, 833, 165, 435, 1, 6, 33, 17, 1707, 5, 1183, 833], [57, 149, 31, 22, 347, 15, 8, 211, 1, 34, 9, 12, 14, 347, 3, 9, 12, 14, 8, 211, 1]]\n[[2077, 6, 200, 17, 7, 3917, 36, 3196, 881, 36, 1252, 27, 125, 3144, 109, 51, 1, 6, 33, 20, 9, 30, 99, 7, 341, 12, 35, 1209, 7, 299, 738, 169, 242, 6, 4225, 4, 20, 394, 155, 1, 6, 2975, 3, 6, 576, 3, 17, 7, 739, 11, 1429, 3, 5821, 418, 3, 2730, 3, 5822, 3, 962, 3, 5, 273, 20, 7, 2819, 125, 64, 4, 4028, 1, 42, 16, 2055, 787, 112, 238, 2, 92, 55, 74, 15, 16, 72, 881, 32, 10, 9, 335, 4, 196, 637, 27, 7, 56], [55, 2, 32, 15, 226, 3, 2, 383, 4, 535, 15, 1028, 953, 1281, 639, 27, 5834, 1, 617, 1263, 5835, 3, 128, 9, 7, 118, 34, 6, 24, 15, 76, 11, 7, 96, 1, 56], [56], [22, 224, 3, 16, 219, 6, 552, 12, 650, 7, 115, 1415, 1, 5836, 5837, 2534, 5838, 518, 5839, 1, 617, 5840, 5841, 2195, 22, 224, 1, 6, 24, 14, 250, 1, 52, 24, 40, 650, 8, 188, 1415, 91, 154, 91, 3, 5, 9, 174, 37, 604, 27, 45, 1, 6, 1131, 4, 606, 10, 40, 165, 487, 435, 24, 26, 435, 1, 67, 20, 14, 391, 155, 3, 5, 67, 24, 14, 1671, 623, 1, 6, 33, 37, 41, 11, 582, 833, 165, 435, 1, 6, 33, 17, 1707, 5, 1183, 833, 56], [149, 31, 22, 347, 15, 8, 211, 1, 34, 9, 12, 14, 347, 3, 9, 12, 14, 8, 211, 1, 56]]\n61.087046632124355\n61.087046632124355\n95\n95\n"
     ]
    }
   ],
   "source": [
    "# Truncate the output to the average length of a comment (203)\n",
    "truncated = []\n",
    "for comment in comments_input_sequence:\n",
    "    if len(comment) > 95:\n",
    "        truncated.append(comment[:95])\n",
    "    else:\n",
    "        truncated.append(comment)\n",
    "comments_input_sequence = truncated.copy()\n",
    "print(comments_input_sequence[:5])\n",
    "truncated = []\n",
    "\n",
    "for comment in comments_output_sequence:\n",
    "    if len(comment) > 95:\n",
    "        truncated.append(comment[:94] + [word_to_index['<END>']])\n",
    "    else:\n",
    "        truncated.append(comment)\n",
    "comments_output_sequence = truncated.copy()\n",
    "print(comments_output_sequence[:5])\n",
    "\n",
    "print(np.average([len(seq) for seq in comments_output_sequence]))\n",
    "print(np.average([len(seq) for seq in comments_input_sequence]))\n",
    "print(max([len(seq) for seq in comments_output_sequence]))\n",
    "print(max([len(seq) for seq in comments_input_sequence]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "padded_post_sequences.shape (965, 203)\npadded_post_sequences[500] [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0   55   52  260  874  377  133  259    3    2  229   77\n   73  101    2  206  918    1   71  220   71   97   62  477   27   19\n    1 4181    3   71   12  736   77  300    5  174   14   62  477   39\n   40   51    3    5    2   26   20   14   83    2   97   22 2074  306\n  918    1    2   20   14   62    4  464   77    5  187  769    1    2\n   26   46   28  151   81   51    1]\n52\n(965, 95)\n[  57   44   50  193    4  283   10    1  200    2  216  244   71  310\n   62  918   59   36  873  216   77  244   34    6  836  264    1   12\n   71  482    4 6772  153   59    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0]\n57\n"
     ]
    }
   ],
   "source": [
    "#PADDING\n",
    "\n",
    "padded_post_sequences = pad_sequences(posts_sequence, maxlen=AVG_POST_LEN, truncating='post')\n",
    "padded_comment_input_sequences = pad_sequences(comments_input_sequence, maxlen=AVG_COMMENT_LEN, padding='post')\n",
    "padded_comment_output_sequences = pad_sequences(comments_output_sequence, maxlen=AVG_COMMENT_LEN, padding='post')\n",
    "print(\"padded_post_sequences.shape\", padded_post_sequences.shape)\n",
    "print(\"padded_post_sequences[500]\", padded_post_sequences[500])\n",
    "print(word_to_index['we'])\n",
    "print(padded_comment_input_sequences.shape)\n",
    "print(padded_comment_input_sequences[500])\n",
    "print(word_to_index['<START>'])\n",
    "\n",
    "# encoder_sequences = tokenizer.texts_to_sequences(posts)\n",
    "# encoder_sequences_padded = pad_sequences(encoder_sequences, maxlen=max_source_length, dtype='int32', padding='post', truncating='post')\n",
    "# decoder_sequences = tokenizer.texts_to_sequences(comments)\n",
    "# decoder_sequences_padded = pad_sequences(decoder_sequences, maxlen=max_target_length, dtype='int32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Layer will consider the top 20000 words and will pad or truncate words to be 200 words long \n",
    "# vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "# text_ds = tf.data.Dataset.from_tensor_slices(comments).batch(128)\n",
    "# vectorizer.adapt(text_ds)\n",
    "# print(vectorizer.get_vocabulary()[:5])\n",
    "\n",
    "#dict mapping words to their indices\n",
    "# voc = vectorizer.get_vocabulary()\n",
    "# word_index = dict(zip(voc, range(len(voc))))\n",
    "\n",
    "embeddings_dictionary = {}\n",
    "with open('./glove6B/glove.6B.100d.txt', 'r') as glove:\n",
    "    for line in glove:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary[word] = vector_dimensions\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 7888 words (565 misses)\n[-0.17791   0.62675   0.4787   -0.55295  -0.84935  -0.070802 -0.34724\n  0.4628    0.12611  -0.24875   0.46881   0.083636  0.56065  -0.21931\n  0.015561 -0.55806  -0.20738   0.9123   -1.2034    0.30115   0.46676\n  0.483    -0.10204  -0.56799  -0.027126  0.40567  -0.14058  -0.55485\n  0.094588 -0.62213  -0.30343   0.60639   0.049799  0.22204   0.48549\n  0.17629  -0.090535  0.53705   0.2755   -0.78827  -0.70953  -0.16678\n  0.11206  -0.48491  -0.66644   0.083952  0.32885  -0.45851  -0.37208\n -1.5315    0.12994  -0.2409   -0.17219   1.374    -0.22313  -2.615\n  0.35201   0.33597   1.6117    0.92947  -0.37535   0.82034  -1.0677\n -0.45329   1.2332    0.23749   0.63523   0.82859  -0.1744   -0.5853\n  0.56339  -0.73094   0.30815  -1.0888    0.46139   0.045386 -0.17827\n -0.054054 -0.8831    0.033935  0.63083  -0.19741  -0.99051   0.20022\n -1.9266   -0.25884   0.10367  -0.34129  -0.93507  -0.54666  -0.40171\n -0.37783  -0.065771 -0.13836  -0.91872  -0.055635 -0.080557 -0.19526\n  0.20078   1.0953  ]\n(8454, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
    "for word, i in word_to_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "\n",
    "print(embeddings_dictionary[\"we\"])\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "source": [
    "<h1>Embedding Layer</h1>\n",
    "The size of the embedding layer is the size of the vector that represents each word. We usually match the size of the embedding layer output with the number of hidden layers in the LSTM cell. \n",
    "\n",
    "The size of the hidden layer is equal to the number nodes representing the signmoid, tanh and hidden state layer in the LSTM cell. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8454\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "embedding_layer = Embedding(vocab_size+1, embedding_dim, embeddings_initializer=Constant(embedding_matrix),  trainable=False)\n",
    "print(vocab_size+1)\n",
    "# embedding_layer = Embedding(vocab_size+1, embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=AVG_POST_LEN, trainable=False)\n"
   ]
  },
  {
   "source": [
    "CREATING THE MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(965, 95, 8454)\n"
     ]
    }
   ],
   "source": [
    "decoder_targets_one_hot = np.zeros((\n",
    "    len(posts),\n",
    "    AVG_COMMENT_LEN,\n",
    "    vocab_size+1\n",
    "    ), \n",
    "    dtype='float32' \n",
    ")\n",
    "print(decoder_targets_one_hot.shape)\n",
    "\n",
    "# # One-hot encoding of the output\n",
    "# num_samples = len(encoder_sequences)\n",
    "# decoder_output_data = np.zeros((num_samples, max_target_length, vocab_size), dtype='float32')\n",
    "for i, seqs in enumerate(padded_comment_output_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        if j > 0:\n",
    "            decoder_targets_one_hot[i, j, seq] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the encoder\n",
    "\n",
    "latent_dim = 256 #LSTM_NODES = latent_dim. Either set to 256 or 50???\n",
    "\n",
    "encoder_inputs = Input(shape=(AVG_POST_LEN,)) # shape=(None,), dtype=\"int64\"\n",
    "enc_emb =  embedding_layer(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the decoder\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(AVG_COMMENT_LEN,)) \n",
    "dec_emb_layer = Embedding(vocab_size+1, latent_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output from the decoder LSTM\n",
    "\n",
    "decoder_dense = Dense(vocab_size+1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "# f = open('../LSTM/model.png', 'w')\n",
    "# f.close()\n",
    "plot_model(model, to_file='../LSTM/model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# import keras\n",
    "# import pydot as pyd\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# keras.utils.vis_utils.pydot = pyd\n",
    "\n",
    "# #Visualize Model\n",
    "\n",
    "# def visualize_model(model):\n",
    "#   return SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "# #create your model\n",
    "# #then call the function on your model\n",
    "# visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(None, 203) (None, 95)\n(None, 95)\n(965, 203)\n(965, 95)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inputs.shape, decoder_inputs.shape)\n",
    "print(decoder_inputs.shape)\n",
    "print(padded_post_sequences.shape)\n",
    "print(padded_comment_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 5.8947 - accuracy: 0.3342 - val_loss: 4.0088 - val_accuracy: 0.4460\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 4.4157 - accuracy: 0.3587 - val_loss: 3.7763 - val_accuracy: 0.4460\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 4.1711 - accuracy: 0.3607 - val_loss: 3.4669 - val_accuracy: 0.4460\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.9091 - accuracy: 0.3752 - val_loss: 3.3840 - val_accuracy: 0.4691\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.8419 - accuracy: 0.3860 - val_loss: 3.3596 - val_accuracy: 0.4685\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.8015 - accuracy: 0.3860 - val_loss: 3.3229 - val_accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.7488 - accuracy: 0.3869 - val_loss: 3.3027 - val_accuracy: 0.4689\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.7014 - accuracy: 0.3885 - val_loss: 3.2776 - val_accuracy: 0.4743\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.6572 - accuracy: 0.3924 - val_loss: 3.2530 - val_accuracy: 0.4770\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.6076 - accuracy: 0.3958 - val_loss: 3.2437 - val_accuracy: 0.4793\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.5748 - accuracy: 0.3983 - val_loss: 3.2265 - val_accuracy: 0.4805\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.5431 - accuracy: 0.3996 - val_loss: 3.2176 - val_accuracy: 0.4807\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.5107 - accuracy: 0.4026 - val_loss: 3.2095 - val_accuracy: 0.4802\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.4808 - accuracy: 0.4042 - val_loss: 3.1966 - val_accuracy: 0.4782\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.4473 - accuracy: 0.4076 - val_loss: 3.1787 - val_accuracy: 0.4819\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.4089 - accuracy: 0.4116 - val_loss: 3.1598 - val_accuracy: 0.4856\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.3715 - accuracy: 0.4158 - val_loss: 3.1486 - val_accuracy: 0.4862\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.3327 - accuracy: 0.4211 - val_loss: 3.1217 - val_accuracy: 0.4953\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.2936 - accuracy: 0.4261 - val_loss: 3.1007 - val_accuracy: 0.4977\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.2546 - accuracy: 0.4293 - val_loss: 3.0848 - val_accuracy: 0.5027\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.2171 - accuracy: 0.4333 - val_loss: 3.0640 - val_accuracy: 0.5019\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.1797 - accuracy: 0.4371 - val_loss: 3.0472 - val_accuracy: 0.5033\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.1434 - accuracy: 0.4398 - val_loss: 3.0335 - val_accuracy: 0.5040\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.1082 - accuracy: 0.4427 - val_loss: 3.0171 - val_accuracy: 0.5081\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 3.0753 - accuracy: 0.4452 - val_loss: 3.0139 - val_accuracy: 0.5074\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.0413 - accuracy: 0.4489 - val_loss: 2.9924 - val_accuracy: 0.5109\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 3.0110 - accuracy: 0.4517 - val_loss: 2.9942 - val_accuracy: 0.5080\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.9798 - accuracy: 0.4540 - val_loss: 2.9772 - val_accuracy: 0.5139\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.9499 - accuracy: 0.4569 - val_loss: 2.9758 - val_accuracy: 0.5138\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.9199 - accuracy: 0.4589 - val_loss: 2.9708 - val_accuracy: 0.5129\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.8909 - accuracy: 0.4619 - val_loss: 2.9702 - val_accuracy: 0.5118\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.8628 - accuracy: 0.4638 - val_loss: 2.9544 - val_accuracy: 0.5163\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.8333 - accuracy: 0.4665 - val_loss: 2.9512 - val_accuracy: 0.5182\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.8070 - accuracy: 0.4687 - val_loss: 2.9593 - val_accuracy: 0.5159\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.7783 - accuracy: 0.4717 - val_loss: 2.9531 - val_accuracy: 0.5186\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.7505 - accuracy: 0.4734 - val_loss: 2.9469 - val_accuracy: 0.5183\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.7239 - accuracy: 0.4771 - val_loss: 2.9457 - val_accuracy: 0.5188\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.6973 - accuracy: 0.4791 - val_loss: 2.9447 - val_accuracy: 0.5190\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.6718 - accuracy: 0.4807 - val_loss: 2.9438 - val_accuracy: 0.5195\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 2.6447 - accuracy: 0.4841 - val_loss: 2.9447 - val_accuracy: 0.5199\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.6182 - accuracy: 0.4875 - val_loss: 2.9470 - val_accuracy: 0.5180\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.5937 - accuracy: 0.4893 - val_loss: 2.9449 - val_accuracy: 0.5221\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.5670 - accuracy: 0.4918 - val_loss: 2.9461 - val_accuracy: 0.5203\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.5414 - accuracy: 0.4946 - val_loss: 2.9406 - val_accuracy: 0.5225\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.5156 - accuracy: 0.4976 - val_loss: 2.9421 - val_accuracy: 0.5216\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.4932 - accuracy: 0.4994 - val_loss: 2.9461 - val_accuracy: 0.5240\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.4678 - accuracy: 0.5028 - val_loss: 2.9451 - val_accuracy: 0.5238\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.4414 - accuracy: 0.5058 - val_loss: 2.9492 - val_accuracy: 0.5245\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 22s 2s/step - loss: 2.4173 - accuracy: 0.5090 - val_loss: 2.9548 - val_accuracy: 0.5233\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.3911 - accuracy: 0.5116 - val_loss: 2.9611 - val_accuracy: 0.5243\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.3680 - accuracy: 0.5137 - val_loss: 2.9546 - val_accuracy: 0.5219\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.3435 - accuracy: 0.5170 - val_loss: 2.9632 - val_accuracy: 0.5250\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.3210 - accuracy: 0.5203 - val_loss: 2.9567 - val_accuracy: 0.5233\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 24s 2s/step - loss: 2.2974 - accuracy: 0.5229 - val_loss: 2.9668 - val_accuracy: 0.5257\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.2696 - accuracy: 0.5271 - val_loss: 2.9679 - val_accuracy: 0.5252\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.2497 - accuracy: 0.5297 - val_loss: 2.9698 - val_accuracy: 0.5274\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.2241 - accuracy: 0.5340 - val_loss: 2.9781 - val_accuracy: 0.5249\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.2019 - accuracy: 0.5368 - val_loss: 2.9765 - val_accuracy: 0.5250\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.1773 - accuracy: 0.5400 - val_loss: 2.9900 - val_accuracy: 0.5252\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.1558 - accuracy: 0.5442 - val_loss: 2.9853 - val_accuracy: 0.5260\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.1310 - accuracy: 0.5465 - val_loss: 3.0029 - val_accuracy: 0.5227\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.1098 - accuracy: 0.5510 - val_loss: 2.9911 - val_accuracy: 0.5251\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.0872 - accuracy: 0.5538 - val_loss: 2.9969 - val_accuracy: 0.5252\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.0622 - accuracy: 0.5582 - val_loss: 3.0037 - val_accuracy: 0.5243\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.0411 - accuracy: 0.5609 - val_loss: 3.0034 - val_accuracy: 0.5247\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 2.0179 - accuracy: 0.5659 - val_loss: 3.0132 - val_accuracy: 0.5237\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.9992 - accuracy: 0.5690 - val_loss: 3.0202 - val_accuracy: 0.5238\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.9716 - accuracy: 0.5736 - val_loss: 3.0198 - val_accuracy: 0.5240\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.9535 - accuracy: 0.5770 - val_loss: 3.0237 - val_accuracy: 0.5251\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.9347 - accuracy: 0.5793 - val_loss: 3.0302 - val_accuracy: 0.5210\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.9108 - accuracy: 0.5854 - val_loss: 3.0353 - val_accuracy: 0.5246\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.8861 - accuracy: 0.5889 - val_loss: 3.0451 - val_accuracy: 0.5240\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.8707 - accuracy: 0.5911 - val_loss: 3.0523 - val_accuracy: 0.5205\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.8482 - accuracy: 0.5946 - val_loss: 3.0483 - val_accuracy: 0.5230\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.8291 - accuracy: 0.5989 - val_loss: 3.0617 - val_accuracy: 0.5220\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.8048 - accuracy: 0.6033 - val_loss: 3.0676 - val_accuracy: 0.5205\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.7868 - accuracy: 0.6065 - val_loss: 3.0701 - val_accuracy: 0.5219\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.7676 - accuracy: 0.6099 - val_loss: 3.0760 - val_accuracy: 0.5220\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.7450 - accuracy: 0.6139 - val_loss: 3.0814 - val_accuracy: 0.5220\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.7271 - accuracy: 0.6177 - val_loss: 3.0932 - val_accuracy: 0.5190\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.7082 - accuracy: 0.6207 - val_loss: 3.0899 - val_accuracy: 0.5211\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.6887 - accuracy: 0.6249 - val_loss: 3.0987 - val_accuracy: 0.5215\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.6672 - accuracy: 0.6287 - val_loss: 3.1140 - val_accuracy: 0.5184\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.6495 - accuracy: 0.6330 - val_loss: 3.1118 - val_accuracy: 0.5180\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.6303 - accuracy: 0.6355 - val_loss: 3.1217 - val_accuracy: 0.5174\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.6132 - accuracy: 0.6396 - val_loss: 3.1267 - val_accuracy: 0.5200\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.5890 - accuracy: 0.6432 - val_loss: 3.1311 - val_accuracy: 0.5187\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.5784 - accuracy: 0.6458 - val_loss: 3.1384 - val_accuracy: 0.5181\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.5568 - accuracy: 0.6491 - val_loss: 3.1409 - val_accuracy: 0.5173\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.5399 - accuracy: 0.6533 - val_loss: 3.1565 - val_accuracy: 0.5180\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.5172 - accuracy: 0.6583 - val_loss: 3.1542 - val_accuracy: 0.5195\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.5053 - accuracy: 0.6602 - val_loss: 3.1622 - val_accuracy: 0.5174\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.4838 - accuracy: 0.6646 - val_loss: 3.1672 - val_accuracy: 0.5165\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.4669 - accuracy: 0.6682 - val_loss: 3.1791 - val_accuracy: 0.5162\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.4540 - accuracy: 0.6712 - val_loss: 3.1802 - val_accuracy: 0.5195\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.4314 - accuracy: 0.6756 - val_loss: 3.1910 - val_accuracy: 0.5159\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.4161 - accuracy: 0.6792 - val_loss: 3.1944 - val_accuracy: 0.5151\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.3976 - accuracy: 0.6830 - val_loss: 3.2080 - val_accuracy: 0.5156\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.3788 - accuracy: 0.6867 - val_loss: 3.2207 - val_accuracy: 0.5144\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 1.3677 - accuracy: 0.6896 - val_loss: 3.2137 - val_accuracy: 0.5147\n",
      "WARNING:tensorflow:From /Users/thiennhan/Desktop/CMPU365_Project/env/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/thiennhan/Desktop/CMPU365_Project/env/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r = model.fit(\n",
    "    x=[padded_post_sequences, padded_comment_input_sequences],\n",
    "    y=decoder_targets_one_hot,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "\n",
    "model.save(\"s2s\")\n",
    "model.save_weights('saved_weights.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "# # Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "plot_model(encoder_model, to_file='../LSTM/model_plot_enc.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = dec_emb_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [h, c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "# decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "# decoder_states2 = [state_h2, state_c2]\n",
    "# decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# # Encode the input sequence to get the \"thought vectors\"\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# # Decoder setup\n",
    "# # Below tensors will hold the states of the previous time step\n",
    "# decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "# decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "# decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "# decoder_states2 = [state_h2, state_c2]\n",
    "# decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# # Final decoder model\n",
    "# decoder_model = Model(\n",
    "#     [decoder_inputs] + decoder_states_inputs,\n",
    "#     [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "\n",
    "plot_model(decoder_model, to_file='../LSTM/model_plot_dec.png', show_shapes=True, show_layer_names=True)\n",
    "encoder_model.save_weights('encoder_model_weights.hdf5', overwrite=True)\n",
    "decoder_model.save_weights('decoder_model_weights.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(None, 203) (None, 256) (None, 256)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'decoder_state_input_h' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7bfcb4377fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_state_input_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_state_input_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs_single\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_state_input_h' is not defined"
     ]
    }
   ],
   "source": [
    "# print(encoder_inputs.shape, encoder_states[0].shape, encoder_states[1].shape)\n",
    "# print(decoder_state_input_h.shape)\n",
    "# print(decoder_state_input_c.shape)\n",
    "# print(decoder_inputs_single.shape)\n",
    "# print(decoder_outputs.shape)\n",
    "# for i in decoder_states_inputs:\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {v:k for k,v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_encouragement(input_seq):\n",
    "    # encoder_model.load_weights(\"../LSTM/encoder_model_weights.hdf5\")\n",
    "    # decoder_model.load_weights(\"../LSTM/decoder_model_weights.hdf5\")\n",
    "    \n",
    "    # # KERAS\n",
    "    # states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # # Generate empty target sequence of length 1.\n",
    "    # target_seq = np.zeros((1, 1, vocab_size))\n",
    "    # # Populate the first character of target sequence with the start character.\n",
    "    # target_seq[0, 0, word_to_index['<START>']] = 1.0\n",
    "\n",
    "    # # Sampling loop for a batch of sequences\n",
    "    # # (to simplify, here we assume a batch of size 1).\n",
    "    # stop_condition = False\n",
    "    # decoded_sentence = \"\"\n",
    "    # while not stop_condition:\n",
    "    #     output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    #     # Sample a token\n",
    "    #     sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    #     sampled_char = index_to_word[sampled_token_index]\n",
    "    #     decoded_sentence += sampled_char\n",
    "\n",
    "    #     # Exit condition: either hit max length\n",
    "    #     # or find stop character.\n",
    "    #     if sampled_char == \"<END>\" or len(decoded_sentence) > AVG_COMMENT_LEN:\n",
    "    #         stop_condition = True\n",
    "\n",
    "    #     # Update the target sequence (of length 1).\n",
    "    #     target_seq = np.zeros((1, 1, word_to_index['<START>']))\n",
    "    #     target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "    #     # Update states\n",
    "    #     states_value = [h, c]\n",
    "    # return decoded_sentence\n",
    "\n",
    "    # # The french one\n",
    "    # print(input_seq.shape)\n",
    "    # states_value = encoder_model.predict(input_seq)\n",
    "    # target_seq = np.zeros((1, 1))\n",
    "    # target_seq[0, 0] = word_to_index['<START>']\n",
    "    # eos = word_to_index['<END>']\n",
    "    # output_sentence = []\n",
    "    # for _ in range(AVG_COMMENT_LEN):\n",
    "    #     # print(states_value)\n",
    "    #     # print(target_seq.shape)\n",
    "    #     # inputs = [target_seq] + states_value\n",
    "    #     # print(inputs)\n",
    "    #     # print(states_value)\n",
    "    #     # for i in range(len(states_value)):\n",
    "    #     #     states_value[i] = np.asarray(states_value[i])\n",
    "    #     # print(states_value)\n",
    "    #     # temp = [target_seq]\n",
    "    #     # print(temp)\n",
    "    #     # temp.append(states_value)\n",
    "    #     for i in [target_seq] + states_value:\n",
    "    #         # print(i.shape)\n",
    "    #     output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    #     idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "    #     if eos == idx:\n",
    "    #         break\n",
    "\n",
    "    #     word = ''\n",
    "\n",
    "    #     if idx > 0:\n",
    "    #         word = index_to_word[idx]\n",
    "    #         output_sentence.append(word)\n",
    "\n",
    "    #     target_seq[0, 0] = idx\n",
    "    #     states_value = [h, c]\n",
    "\n",
    "    # return ' '.join(output_sentence)\n",
    "\n",
    "    # The weird one\n",
    "    # #Getting the output states to pass into the decoder\n",
    "    # states_value = encoder_model.predict(input_seq)\n",
    "    # #Generating empty target sequence of length 1\n",
    "    # target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "    # #Setting the first token of target sequence with the start token\n",
    "    # target_seq[0, 0, word_to_index['<START>']] = 1.\n",
    "    \n",
    "    # #A variable to store our response word by word\n",
    "    # decoded_sentence = ''\n",
    "    \n",
    "    # stop_condition = False\n",
    "    # while not stop_condition:\n",
    "    #   #Predicting output tokens with probabilities and states\n",
    "    #   output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "    #   #Choosing the one with highest probability\n",
    "    #   sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    #   sampled_token = index_to_word[sampled_token_index]\n",
    "    #   decoded_sentence += \" \" + sampled_token#Stop if hit max length or found the stop token\n",
    "    #   if (sampled_token == '<END>' or len(decoded_sentence) > AVG_COMMENT_LEN):\n",
    "    #       stop_condition = True\n",
    "    #   #Update the target sequence\n",
    "    #   target_seq = np.zeros((1, 1, vocab_size+1))\n",
    "    #   target_seq[0, 0, sampled_token_index] = 1.\n",
    "    #   #Update states\n",
    "    #   states_value = [hidden_state, cell_state]\n",
    "    # return decoded_sentence\n",
    "\n",
    "    #Marathi one\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = word_to_index['<START>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_word[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<END>' or len(decoded_sentence) > AVG_COMMENT_LEN):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-\n",
      "Post:  i 19f just broke up with my boyfriend 22m i am heartbroken and lost . i met him a couple months ago and i fell so hard and so fast for him . now i dont have anything . i knew he was the one , i knew he would be the one who i would marry and be there till the end . i have messed up so bad and theres nothing i can do . i feel so hopeless . . i lost my soulmate , he was and still is my everything . i dont wanna live my life without him . i cant keep dealing with heartbreak . this has happened too many times . i cant do it . when im heartbroken i get really bad depression . im taking medicine for it but it still hurts . for once can i be treated right . . do i not deserve anything good in my life ? am i not deserving of love ? is there something wrong with me ? am i unloving . . i need encouragement that its gonna be okay because i have no one else . . please help me .\n",
      "Generated Comment:   all of the same thing . i know that is a lot of people and do not know about your own . i just have\n",
      "Actual Comment:  <START> this shit aint easy . its gonna suck for a good while . the good news is youre 19 , and havent even come close to meeting all the people who will love you in your life . its hard to see the bright side right now , and you shouldnt force it . feel all the things youre feeling and let them teach you something . youre gonna make it out of this it doesnt feel like that right now and it wont for awhile . wallowing in fine for now . love yourself as much as you can , whenever wherever you can\n",
      "-\n",
      "Post:  keep your fingers crossed , pray , or just send positive vibes my way please !\n",
      "Generated Comment:   , friend , i am in a good place in my life . i am not a lot more than not . i am not a lot more\n",
      "Actual Comment:  <START> good luck , we believe in you !\n",
      "-\n",
      "Post:  i want to learn to draw , speak japanese , try and get some episodes transcripted , and write , but i cannot get myself off my phone or out of bed and doing anything . encouragement ? hopedully i am using this sub right sorry if i am not\n",
      "Generated Comment:   , i am not the same way . but it is not a great thing to live . i hope you do well for you . i am\n",
      "Actual Comment:  <START> hi , internet friend ! i totally get this . i want to get a graphic design business going nothing major , just something small , but i have a very hard time getting started . something that helps me is setting very specific goals for myself by halloween , i will add 15 pieces to my portfolio . this week , i will collect public domain clip art . next week , i will _____ . today , i will _____ . concrete goals help a lot ! just make them small enough that you can see results quickly . download an app for learning japanese today . tomorrow , practice for 10 minutes . 20 the next day . practice drawing eyes and fill one page tomorrow , fill two . you will see progress , and that will give you encouragement beyond what anyone could give you in words ! also , you want to do these things because you love them ! they are fun . make sure you are having fun doing these things you love ! best of luck ! i am sure you will be wonderful !\n",
      "-\n",
      "Post:  hi . my person found out he will have to do chemo for the next few months after a ct scan found that his tumor which got removed three weeks back had metastasized . i am trying not to freak out , and mostly am doing okay , but part of me is super terrified that my best friend will die and leave me , and we have only been married two years . i appreciate any kind words or thoughts you have , and thank you for your time .\n",
      "Generated Comment:   all of cancer has improved the same thing . the world is a lot of a pen and a scrap of paper . do\n",
      "Actual Comment:  <START> treatment of cancer has improved incredibly in recent years . we will be thinking positive thoughts for you .\n",
      "-\n",
      "Post:  i work 3 jobs right now , and am part of a mentorship program . i could just work the one and pay my bills . i just have such bigger dreams than where i am now . it is just fucking exhausting . i just need to know it will be worth it .\n",
      "Generated Comment:   , i am sorry to hear about this . i was in my similar position . i am not a lot of lots of mental\n",
      "Actual Comment:  <START> dude you are freaking amazing . i am considering working two part time jobs along study , but even that will be tough , and i will probably drop one . i think as long as you have a day to yourself a week , with no responsibilities , you can tough it out for a while . make sure you write regular , achievable goals for yourself and hit them hard !\n"
     ]
    }
   ],
   "source": [
    "# for _ in range(5):\n",
    "# for seq_index in range(2):\n",
    "#     # Take one sequence (part of the training set)\n",
    "#     # for trying out decoding.\n",
    "#     input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "for _ in range(5):\n",
    "    i = np.random.choice(len(posts))\n",
    "    input_seq = padded_post_sequences[i:i+1]\n",
    "    generated_comment = give_encouragement(input_seq)\n",
    "    print('-')\n",
    "    print('Post: ', posts[i])\n",
    "    print('Generated Comment: ', generated_comment)\n",
    "    print(\"Actual Comment: \", comments_input[i])"
   ]
  },
  {
   "source": [
    "Keras LSTM Architecture\n",
    "\n",
    "The input shape of the text data is ordered as follows: batch size, number of time steps, hidden size (size of the hidden layer)\n",
    "For each batch sample and each word in the number of time steps, there is a l500 length embedding word vector to "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('saved_weights.hdf5', overwrite=True)"
   ]
  }
 ]
}