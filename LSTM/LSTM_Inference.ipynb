{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1>LSTM Inference Model for Encouragement Generator</h1>\n",
    "CMPU 365\n",
    "Jason Lee, Nhan Nguyen\n",
    "\n",
    "We have consulted and adapted code from the following sources in the making of this model: \n",
    "- https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/\n",
    "- https://keras.io/examples/nlp/lstm_seq2seq/#run-inference-sampling\n",
    "- https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.losses import cosine_similarity\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import csv\n",
    "from CleanText import clean_text\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_method = \"embed\" #embed\n",
    "# Use \"embed\" for word embedding output"
   ]
  },
  {
   "source": [
    "<h3>Load constsnts</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_char = \"<START>\"\n",
    "end_char = \"<END>\"\n",
    "post_len = 251\n",
    "comment_len = 116\n",
    "word_to_index = {}\n",
    "with open(\"word_to_index.csv\", 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # toss headers\n",
    "    for word, index in reader:\n",
    "        word_to_index.setdefault(word, int(index))\n",
    "index_to_word = {v:k for k,v in word_to_index.items()}\n",
    "\n",
    "embeddings_file_name = \"embeddings_tokenized_one-hot.npy\" if decoder_method == \"one-hot\" else \"embeddings_tokenized_embed.npy\"\n",
    "\n",
    "with open(embeddings_file_name, \"rb\") as embeddings_file:\n",
    "    embeddings_tokenized = np.load(embeddings_file)"
   ]
  },
  {
   "source": [
    "<h3>Construct Inference Model</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder inputs:  (None, 116)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"One-Hot_Model\" if decoder_method == \"one-hot\" else \"Embed_Model\"\n",
    "model = load_model(model_name)\n",
    "# Get the latent_dim from the model\n",
    "latent_dim = model.layers[4].output[0].shape[1]\n",
    "\n",
    "# Create encoder\n",
    "encoder_inputs = model.input[0] #input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Create decoder\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "dec_emb_layer = model.layers[3]\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = model.layers[5]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    dec_emb, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[6]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "print(\"Decoder inputs: \", decoder_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_encouragement(input_text):\n",
    "    \"\"\"\n",
    "    Use the model to produce output given an input sequence\n",
    "    Input: input_text, input that the model will generate text for\n",
    "    Output: a string representing the output of the model \n",
    "    \"\"\"\n",
    "    # Convert string to padded sequence of integers\n",
    "    input_sequence = clean_text(input_text)\n",
    "    input_sequence = [word_to_index[x] for x in input_sequence]\n",
    "    input_sequence = pad_sequences([input_sequence], maxlen=post_len, truncating='post')\n",
    "    # Get internal state of encoder\n",
    "    states_value = encoder_model.predict(input_sequence)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Start output with the start symbol\n",
    "    target_seq[0, 0] = word_to_index[start_char]\n",
    "    stop_condition = False\n",
    "    output = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h_state, c_state = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_word = \"\"\n",
    "        sampled_token_index = 0\n",
    "        if decoder_method == \"one-hot\":\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = index_to_word[sampled_token_index]\n",
    "        else:\n",
    "            similarity = math.inf\n",
    "            for i in range(embeddings_tokenized.shape[0]):\n",
    "                new_sim = cosine_similarity(embeddings_tokenized[i:i+1].astype('float32'), output_tokens[0, 0].astype('float32'), axis=-1)\n",
    "                if new_sim < similarity:\n",
    "                    similarity = new_sim\n",
    "                    sampled_token_index = i\n",
    "            sampled_word = index_to_word[sampled_token_index]\n",
    "        output += ' '+sampled_word\n",
    "        if (sampled_word==end_char or len(output)>comment_len):\n",
    "            stop_condition = True\n",
    "        # Reset target_seq, pass current states forward\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h_state, c_state]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n",
      "Post:  We get a late start to look for a room and of course all of them are occupied.We return to the common area, and he gets an attitude and starts to pout and scroll on his phone and refuses to do the activity with me in the common area.\n",
      "Actual comment:  I hear parenthood refocuses a person's priorities and perspective on life. The realization that a new human being -- their well-being, education, role-models, their entire future!-- depends on you *should* be a life-changing experience. Unfortunately, many parents seem unable to put their children first.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 116) for input Tensor(\"input_2:0\", shape=(None, 116), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
      "Generated comment:   i know someone here already said this , but if you need to talk or vent , please pm me . good luck ! you got this ! was\n",
      "Post:  It is now week 3 of my first ever internship and every day I come home feeling worse about myself and how things are going. I try to ask questions but a lot of times I feel like Im so confused I dont know where to start or my manager is not there and i dont even know who to go to for questions. When he is there and I ask questions he always seems to answer in a way that makes me feel stupid and like I should have just figured out the answer on my own. I am currently working on 3 projects and a couple side projects for my managers boss. Not sure if that is normal or not but I am feeling very  overwhelmed and anxious. Im just tired of coming back to my apartment everyday feeling like Ive accomplished nothing again, I am constantly wondering why I was hired for this position when I know so many others that would probably do better. I just want to feel like I did something right at work : ( \n",
      "Actual comment:  People survive their internships and live to tell the war stories later.=)Oh, and keep asking all the questions. If you ask enough questions, one of two things will happen:1) you will get the answers. OR2) people will get nervous and give the extra work to someone else.;)\n",
      "Generated comment:   so i know you can do it you can do it ! just want to do so come so get you you come just make it . was this this so you\n",
      "Post:  So I went from $60 to $8 cause I didn't know my netflix bill and hulu bill happened today. So after I bought drinks and two cool bracelets for myself, I didn't have enough money to buy my pizzas. I was at target and I had put two digornio's stuffed cheese pizzas in my cart and I was trying to check my bank finances cause I always get paranoid that money is going to disappear. But I had $40 after I bought my bracelets. So I knew I had enough....but when I saw I only had $8. My heart sank....because....I'm the type of person who never buys anything for myself because I have always been broke. I have been scammed out of money through my parents. I have had precious items sold from under my nose by family.....I once had a $100 electoric guitar and $50 amp bought for christmas one year....I didn't even have that for a year.\n",
      "Actual comment:  But i made sure that I was saving enough to I could buy the stuff. I got on the bus.\n",
      "Generated comment:   i was at target and i had put two 2114 stuffed cheese pizzas in my cart and i was trying to check my bank finances cause\n",
      "Post:  Ghosted by my college friends when I had a family medical emergency and had to withdraw from school, and my best friend blocked me on everything in December. The only explanation I can think of for getting blocked is that she was hoping this guy (who she said had major insecurity issues) would ask her out, and my assumption is that he made her block me.Student loans are beating me down because I dont know if its financially worth it to shoot for my dream. What good is it if I have to work a job in addition to my career just to pay off my loans?Im just having a rough time, and its getting to meEdit: I also find myself misdirecting my anger because Im so upset with my life. Thats actually what led me here\n",
      "Actual comment:  Give things some time to straighten out, and straighten yourself out with it. Don't Force it too much right now. There are some communities that might be able to help you out here too. r/mentalhealth is one of them.\n",
      "Generated comment:   i 'm i i never i have could should come have could want you to make you might not you not should you so you are get it\n",
      "Post:  Ok so I'm pretty freaked out right now. Both because this is my first time posting, and because today I posted my first (and very rough) YT video.Some context: I live away from my family, they're in Indonesia and I'm in Sydney. I visit every year for Xmas, but this time it got sadder to go back to work after the holidays. I realised that I'd usually keep my head down at work for a whole year, and it started to feel sad and pointless. When I met up with a close friend while I was home, we talked about what really makes you feel happy, and singing is something that came up for as I felt it was like an outlet.\n",
      "Actual comment:  Your singing is actually pretty good. I think if you just keep practicing and learning from singing lessons, youll do great. Some of the other singers Ive seen play the guitar and sing in separate intervals, then mix the audios in editing. Maybe you can try that.\n",
      "Generated comment:   i really like your singing ! you should definitely keep practicing ! was going to be really well while you you could\n",
      "Post:  Keep your fingers crossed, pray, or just send positive vibes my way please!\n",
      "Actual comment:  Sending prayers and vibes!\n",
      "Generated comment:   good luck , we know you you you would not not not not because what did it if be that really it you will come come just\n",
      "Post:  I'm feeling really low. A few months ago on I was promoted to my first management position. I was so excited to be In leadership and I really thought I could make a difference in someone's career. About 2 months ago I got my team, all new hires, and almost all straight out of  college with little or no job experience. They are so rough. After rigorous training almost all of them are rough, to be expected of course.What I wasnt expecting is to have 4 HR issues right of the bat and them escalating me to leadership above me. I have 3 that are are written warnings for attendance, 1 more and will be termed. 1 went to my leadership and asked if I was right. Unfortently I so know this may happen as people might be unhappy, especially if they are having performance issues. All day my leaders tell me that i have such a bad team and they feel so bad for me, that I'm doing great handling it and it's really breaking me in.\n",
      "Actual comment:  I guess just try and make sure they don't ruin you for the next new people to come under you.  Can you take this to your supervisors and get them to smash some sense into these guys?\n",
      "Generated comment:   if you know all your what so what you want to you . but you you know you can do it ! i know you can do this ! ! ! ! !\n",
      "Post:  Im in too low of a funk to consistently care about maintaining my beard which is as frustrating as daily care would be. Ive been gaining fat all of 2020 which not only do I want to lose weight but Im also a nutrition major so thats not a good look. Ive been having toenail issues for about a year now, which tops it off for the head to toe partIm unemployed right now and couldnt get unemployment, so thats really rough. Im really thankful that money isnt as big of an issue as it would be for most people, but I find myself sitting in my car in a random parking lot just to get out of the house. I legit lost all of my friends in 2019 with not even the slightest explanation.\n",
      "Actual comment:  I am so sorry that you're dealing with all of this right now, and I so wish that I could say something that would help. I understand where you're at right now.\n",
      "Generated comment:   i 'm i i never i have could should come have could want you to make you might not you not should you so you are get it\n",
      "Post:  Hi. I finished my original degree 17 years ago and have worked in IT since then but the past year had really made me fall out of \\~\\~love\\~\\~ like with that. I've wanted a masters for a long time with the idea that eventually I'd pursue a new career as a public policy analyst so I've gone back to undergraduate courses in economics and math with the idea if I do well I'll pursue a masters in economics but if not maybe public policy or political science or just go back to work. Of note I'm married with a 6 moth old daughter.Well...I showed up to my first calculus test (I originally passed it with an 89.6 in 2002 but am retaking it to prepare for calculus II) and the teacher told us we couldn't use our calculators and to put them away. We all panic. I didn't even finish the test.\n",
      "Actual comment:  Maybe there are people in your class you could potentially reach out to and have study sessions?\n",
      "Generated comment:   you get this come but they we sure so come . was . . . i think so look but you know that so not only this what go have\n",
      "Post:  I try to stay in my room and not make a mess. I try to get up with my niece and let my brother and sister sleep in when I am able. I haven't even been there 6 months. My sister in law expressed that she wanted me out last night. After they encourage me to go to my best friend's wedding in another state and get involved in a local sport (which cost money), I was informed that she was pissed that I had bought sports equipment the other night and that it was becoming time for me to leave. She wasn't mean about it. She just stated that it was time for her to have her space back. I'm worried that after all the changes I have been making, I'm back where I started. I'm in a job that can't sustain me financially. I don't know how I'm going to afford my bills if I move out by February.\n",
      "Actual comment:  I don't always try my best because I get scared of success or failure or (imaginary) public opinion, or all the above. So maybe find a different way to redirect frustration or stress - whether it's through art, exercise, writing, music... whatever positive outlets you find meaningful.\n",
      "Generated comment:   i am sorry to hear you are going through this . for whatever little it might be worth , you sound to me like a strong\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "comments = []\n",
    "with open('../splitted_data_3.csv', 'r', newline='') as csv_file:\n",
    "    textReader = csv.reader(csv_file)\n",
    "    for row in textReader:\n",
    "        posts.append(row[1])\n",
    "        comments.append(row[0])\n",
    "\n",
    "posts = posts[-10:]\n",
    "comments = comments[-10:]\n",
    "\n",
    "print(len(posts))\n",
    "\n",
    "for i in range(len(posts)):\n",
    "    print(\"Post: \", posts[i])\n",
    "    print(\"Actual comment: \", comments[i])\n",
    "    print(\"Generated comment: \", give_encouragement(posts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}